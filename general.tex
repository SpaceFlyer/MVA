\section{The General Case}
\label{sec:general}

In this section, we drop the constraints that (1) the mechanism must
allocate efficiently and (2) bidders have no cost for bidding ($\beta_2=0$), and prove that MVAs are optimal
even without these constraints (i.e., in the fully general model).  We also
study methods for finding the specific optimal MVA, though we do not manage
to obtain a characterization that is as elegant as in the restricted case.
%which turns out to be significantly more complex than previous
%simplified case.

%Let us first look at bidder's bid cost.  Sending emails, making phone
%calls, entering credit card nubmers, depositing money and clicking buttons are
%all costly for bidders, though sometimes very tiny.  Bidders may not bid when
%this cost is greater than their expected utility. Note that even if the
%valuation is very high, the expected utility can be very small because of tense
%competition, which is very common on the Internet as $n$, the number of
%potential bidders, is very large.

%The first constraint we are going to remove is seller's cost only.  It is
%exciting to introduce bidder's bid cost since it occurs very often in real
%cases and it plays an important role.  Sending emails, making phone calls,
%enterring credit card nubmers, depositing money and clicking buttons are all
%costly for bidders, though sometimes very tiny.  Bidders may not bid when this
%cost is greater than their expected utility. Note that even if the valuation is
%very high, the expected utility can be very small because of tense competition,
%which is very common on the Internet as $n$, the number of potential bidders,
%is very large. 

An interesting effect of $\beta_2>0$ is that it gives bidders an incentive
{\em not} to bid when they expect many others to bid, because if they do
not win they still pay $\beta_2$ for bidding. (Also, we note that their
probability of winning with a fixed value is exponentially small in the
number of bidders, so that even small bidding costs, such as the effort
needed to send an e-mail, can be significant.)  This effect is rather
opposite to the effect observed in earlier parts of this paper that bidders
are less inclined to wait for later rounds when there are many bidders.

%This behaviour (bidders will not bid because of competitions) is very different
%compared to that in previous model \cite{McAfee97:SequentialAuctions} of
%sequential auctions. In that model, there is a time discount which
%makes bidders eager to bid in early rounds with high reserve prices to avoid
%waiting lost. 
%That makes a lot sense in some cases but sometimes it may not.
%For example, 
%Suppose that the seller posts an auction with a very low reserve price in
%the first round, most bidders with high valuation must be happy to bid
%according to that time discount cost model. But in our model, a lot bidders
%may be reluctant to bid because of competence, which can hurt seller's revenue.

%But this may not be true. For
%example, when I encounter such an auction online \footnote{For example, when I
%see a very good item in the Auction House of Diablo III with a very low current
%bidding}, I might be very reluctant to bid because there is a big probability
%that my bidding will be over taken by someone else's so it is just a waste of
%effort. Our cost model can describe this behaviour very well.

%Assume an extreme case where the broadcast cost is $0$, the bidder's bidding
%cost is $0.1$ and there are $n \rightarrow \infty$ many $[0, 1)$-uniform
%distributed bidders. In a Dutch auction (a Dutch auction has infinite many
%rounds of broadcasts so we have to set braodcast cost to $0$), only one bidder
%is expected to bid (no competition), thus every bidder with a valuation $v_i
%> 0.1$ should be benifitable to bid when the reserve price drops to a little
%bit below $v_i-0.1$ (recall that $n \rightarrow \infty$).  In a Vickrey
%auction, however, the competition is very tense. Only bidders with valuation
%greater than $t$ can accept such intense competition where $t$ satisfies
%$t^{n-1}t - 0.1 = 0$ (the expected utility for a bidder with valuation $t$ is
%$0$).  Thus $t = \sqrt[n]{0.1}$ which is arbitrary close to $1$ as $n$ grows to
%infinity.  Thus almost all bidders cannot bare this competition when $n$ is
%really large.
%
%So a mechanism (e.g. a Vickrey auction) with too much bidders' bid cost
%(competence) will have less participations and therefore may decreases seller's
%profit significantly.  To see this, look at previous extrame case again.  The
%revenue of Dutch auction will converge to $0.9$ (someone with valuation very
%close to $1$ will bid for price very close to $0.9$) when $n$ becomes infinity.
%The revenue of a Vickrey auction, however, is only $\int_t^1 x \, (n-1) \,n\,(
%1-x) \,{x}^{n-2} dx$ which converges to about $0.67$ when $n$ grows to
%infinity.  


\subsection{Spending Equivalence Theorem}
% and Revenue Optimization Strategy}

Another effect of $\beta_2>0$ is that the revenue equivalence theorem
(straightforwardly interpreted) is no longer applicable, because this theorem 
assumes
that the utility is equal to valuation minus payment, which is no longer
true because cost also plays a role.  Intuitively, we can fold this cost
into the payment to make the theorem applicable again, though we have to
keep in mind that this cost does not benefit the seller, unlike (true)
payments.  This is how we proceed.



%This assumption is no longer true as now the utility is also
%influenced by the cost charged to this bidder. And even if the bidder doesn't
%win, the cost still exists so we can't simply revise the valuation.

%Therefore, the first issue we are going to solve is to make a very similar
%theorem applicable to our model again. 

\begin{theorem}[Spending equivalence]\label{theorem:equivalence}
The bidders' total spending (expected payment + bidding costs)
is completely determined by (1) the expected utility of
lowest-type bidders and (2) the allocation probability function
$$p: (v_1, v_2, \ldots, v_n) \rightarrow (p_1, p_2, \ldots, p_n)$$ 
where $p_i$ is the probability that bidder $i$ will get the item.
\end{theorem}
%vc: maybe define "sketch of proof" environment
\begin{proof}
  Any mechanism in our domain (with bidding costs) can also be used in a
  domain without costs, letting the seller collect the bidding costs (as
  well as the payments) instead.  The bidders' incentives will be identical
  in this mechanism, and so the result follows from applying the
  standard revenue equivalence theorem to these transformed mechanisms.
%To prove it, let us construct another mechanism
%$M'$ without bid cost from our mechanism $M$ with bid cost so $M'$ fits
%into the original revenue equivalence theorem's model. Suppose there is a
%virtual seller in $M'$, who collects valuations from all bidders at no cost (a
%direct revelation mechanism). Then this virtual seller will make $n$ virtual
%bidders delegating bidders to communicate with the true seller in our mechanism
%$M$.  When our mechanism ends by allocating the item to virtual bidder $i$, the
%virtual seller also allocate the item to the real bidder $i$. The payment from
%each bidder $i$ to this virtual seller will be equal to the payment that
%virtual bidder $i$ pays to our real seller plus all the bid costs charged
%to virtual bidder $i$.
%$M'$ will satisfy revenue equivalence theorem and
%%Thus, from the real bidders' aspects, this mechanism
%%$M'$ is just a direct revelation mechanism which will satisfy revenue
%%equivalence theorem. 
%the payment from real bidder
%$i$ to the virtual seller has two parts, one payed to the real
%seller, another consumed by bid costs, which sum up to total spending.
\end{proof}


This greatly simplifies our profit maximization problem:
%Thanks to Theorem~\ref{theorem:equivalence}, our profit maximization problem
%is now greatly simplified: 

\begin{corollary}
To maximize profit for a fixed allocation rule $p: (v_1, v_2, \ldots, v_n)
\rightarrow (p_1, p_2, \ldots, p_n)$, it suffices to minimize total cost
(including both seller's cost and bidders' cost).
\end{corollary}
\begin{proof}
The seller's profit is $\text{revenue} - \text{seller's cost} =$\\$
(\text{bidders' spending} - \text{bidders' cost}) - \text{seller's cost} = 
\text{bidders'}$\\$ \text{spending} - \text{total cost}$, and bidders' spending is
fixed by Theorem~\ref{theorem:equivalence}.
%The total spending, substracts cost charged to bidders, will be the revenue
%that the seller receives.  This revenue, substracts cost charged to the seller,
%will be profit. Thus profit is total spending minus total cost. As total
%spending is fixed by allocation rule, we only need to find the minimum cost to
%maximze profit.
\end{proof}

%The highlight here is that we will not have to differentiate cost charged to
%bidders and cost charged to sellers if we just want to maximize seller's profit.
%The difference of them may make revenue different, but as long as their sum
%does not change, the profit will not change. This not only helps us simplify our
%analysis, but also helps us simplify the optimal mechanism: 

%\begin{figure*}
%\centering
%  \subfigure[Best query length $x$ over $h$ with fixed $l$]{
%    \includegraphics[trim=0mm 5mm 5mm 15mm, clip, width=.4\linewidth]{figures/1000-500-2-1-10}
%    \label{fig:x-h}
%  }
%  \subfigure[Normalized best query length $x$ over low value $l$]{
%    \includegraphics[trim=0mm 5mm 5mm 15mm, clip, width=.4\linewidth]{figures/10000-500-2-1-10}
%    \label{fig:x-l}
%  }
%  \caption{In the first subfigure, we plot the best query length $x = \hat x / D$ over $h = \hat h / D$ (the highest
%      undiscovered value) with discretized low value $\hat l = 500$,
%      broadcast bid cost ratio $\rho = 2$,
%      number of bidders $n = 10$ and maximum discretized valuation
%      $D = 1000$. In the second subfigure, we normalize $x$ to be $x = \hat x / \hat h$ and
%      $l$ to be $l = \hat l / \hat h$, as if $h$ is always $1$.}
%\end{figure*}


\subsection{MVAs' Optimality in General}

It is important to note that when $\beta_2 > 0$, the bidders' incentives
have changed, and if we wish to achieve given  thresholds $a_1, a_2,
\ldots$ using an MVA, just setting the reserve prices $r_1, r_2, \ldots$
according to Lemma~\ref{lemma:sufficient} will not suffice.  For example,
if we set the reserve prices in this way,
it may be the case that $\beta_2 > a_i - r_i$, in which case it would be
clearly suboptimal for a bidder with valuation $a_i+\epsilon$ to bid in
round $i$.
Rather than
adjust the reserve prices, we can employ a simpler trick: for every bid
that is placed, the seller can pay that bidder $\beta_2$, thereby absorbing
the cost of the query.  By doing so, the bidders' incentives are as they
were before, 
%and while this payment comes out of the seller's revenue, 
and by
Theorem~\ref{theorem:equivalence} this will lead to the same profit as any
other mechanism with the same query costs and allocation probabilities.
We will still consider a mechanism with such refunds an MVA.


%\begin{proposition}
%In original MVA, to make a set of thresholds $a_i$ works (the
%equilibrium holds), we may have to make $r_i$ negative. That says, we need to
%compensate bidders if only one bids at reserve price $r_i$ rather than charge
%him something, in order to maintain bidders incentive to bid in spite of
%bid cost. That's not intuitive and sellers/bidders may
%not be able to easily understand it. A better way to achieve $a_i$ might be
%compensating the bidder with the bid cost immediately after the bidding.
%Equivalently, the seller buys the bid cost for bidders and make it as a
%part of seller's bid cost. This won't change his profit but this will make
%everything looks more intuitive ($r_i$ is non-negative again).
%\end{proposition}

By Myerson's result, to maximize expected total {\em bidder spending}, we need to
maximize the expected virtual value of the winning bidder.  
Because we are considering cases with symmetric priors, this results in a
Vickrey auction with a reserve price that corresponds to a virtual
valuation of zero.
However, we are
interested in profit, not spending.  Not only does this mean that we need
to plan our queries carefully, but it can also affect the allocation rule.
For example, increasing the final reserve price (below which we do not
allocate) slightly above Myerson's reserve price may increase profit,
because it will reduce communication costs.  Still, we can build on
Myerson's result to show that MVAs (generally with a final reserve price
above $0$) are optimal.


%Since profit is total spending minus overall cost where total spending is
%decided by allocation rule which is studied in Myerson's work, our optimizing
%problem is greately related to Myerson's if we were able to minimize the
%overall cost. However, the optimal allocation rule here is not as simple as the
%one that is discovered by Myerson \cite{Myerson:1981}: allocate the item to the
%bidder with highest positive virtural value.  Theorem~\ref{theorem:equivalence}
%tells us that this rule will maximize the total spending.  But we must
%substract the cost from the spending to get the profit.  Therefore, there might
%be another weird allocation rule that has less total spending but even much
%less minimum cost.

%It is not hard to find one example of this. We know that for bidders
%with uniform valuation over $[0, 1)$, the spending maximizing allocation rule
%is allocate the item to the bidder with highest valuation that is greater than $1/2$.
%However, if the broadcast cost is too large, for example $1$ (which is equal to the
%highest possible valuation), the cost to find out whether there is any bidder with valuation
%greater than $1/2$ is at least $1$. Thus if we use this allocation rule, the
%final profit would be negative since the total spending must be less than the
%minimum cost. However, the allocation rule that never allocate the item will have
%$0$ cost and $0$ spending, which achieves $0$ profit, better than previous allocation
%rule.

%Thus, the profit optimal mechianism will depend on how minimum cost is defined given an allocation rule. 

%We previously defined how cost is charged and proved that a specific mechanism (MVA)
%has minimum cost when allocation rule is allocate efficiently. But unfortunately,
%that is not enough to give us a well defined minimum cost for any allocation rule.
%For example, one allocation rule might be always allocate the item to each bidder
%with the same probability $1/n$, i.e. $p(v_1, v_2, \ldots) = (1/n, 1/n, \ldots)$.
%One might think that the minimum cost for this is $0$ since we do not have to know
%anyone's valuation. But that cost is not realistic: how can the mechanism ever allocate the
%item to someone that it has never communicated with? Thus the minimum cost seems
%to be at least $b$, the cost for one round of broadcast, if we ever allocate the item
%to some bidder. In order to make a realistic constraint and get a well defined minimum
%cost for any allocation rule, we define

%\begin{definition}\label{def:allocation_cost}
%A mechanism with allocation rule $$p: (v_1, v_2, \ldots, v_n) \rightarrow
%(p_1, p_2, \ldots, p_n)$$ does not allocate blindly if it satisfies: if $p_i >
%0$ for some valuation profile $(v_1, v_2, \ldots, v_n)$, there must be a
%broadcast query that the $i$-th bidder ($v_i$) reply to the seller
%under that profile setting.
%\end{definition}

%The no-blind-allocation property defined above will ensure the optimality
%(minimum cost) of the following mechanisms.


%\begin{definition}
%A mechanism satisfies {\em relaxed efficiency with low value $l$}
%if it does not allocate the item when all valuations are below $l$, and
%otherwise allocates to the bidder with the highest valuation.
%Mechanisms satisfy relaxed efficiency constraint with low value $l$
%if they always allocate the item to the bidder with highest valuation that's
%at least $l$ (no allocation if everyone is below $l$).
%
%    \begin{enumerate}
%
%    \item They only allocate the item to bidders whose valuation are at least
%    $l$ (the low value is $l$)
%
%    \item If they will allocate the item, they will always allocate the item to
%    the bidder with highest valuation.
%
%    \end{enumerate}
%
%When we say a mechanism has a low value $l$, we imply that it
%satisfies relatex efficiency constraint with low value $l$.
%\end{definition}

%With this definition, we have

\begin{theorem}
  Under a regularity condition on the PDF 
 (implying the virtual valuation is strictly
%vc: is strictly necessary?
  increasing~\cite{Myerson:1981}),
there exists 
an optimal MVA.
%an  optimal mechanism satisfying relaxed efficiency (for some
%value $l$).
%The optimal mechanism should always allocate the item to the bidder with
%highest virtual valuation $v_i - \frac{1-F(v_i)}{f(v_i)}$ if it decides to
%allocate the item. In regular cases when the virtual valuation is monotone
%strictly increasing, the optimal mechanism should always allocate the item to
%the bidder with highest valuation if it decides to allocate the item.
\end{theorem}

%vc: maybe make sketch
\begin{proof}
Consider any optimal mechanism given by a
query strategy $S(f, m, V, \mathcal Q)$ (see Definition~\ref{def:query}) and an
allocation function based on $V$, the set of reported values.
% (due to the
%no-blind allocation condition (Definition~\ref{def:allocation_cost}, it
%cannot depend on anything else)).
%since we can
%only allocate item to reported bidders. 
We then construct another mechanism
with query strategy $S'(f, m, V', \mathcal Q')$ where $\mathcal Q'$
consists of descending queries
and 
\begin{align*}
|S'(f, m, \emptyset, \{Q'_1, \ldots, Q'_{i-1}\})|_f %= |Q'_i| = |Q_i|\\
  = |S(f, m, \emptyset, \{Q_1, \ldots, Q_{i-1}\})|_f
\end{align*}
If $S(f, m, \emptyset, \{Q_1, \ldots,
Q_{i-1}\})=\emptyset$ (termination), then it also has
$S'(f, m, \emptyset, \{Q'_1, \ldots, Q'_{i-1}\})=\emptyset$ 
and the item is not allocated in this case.
%Done vc: maybe move this earlier? |Q|_f
Under $S'$, once at least one bidder bids, we allocate to the highest
bidder (and payments are set to incentivize truthful reporting, as
discussed earlier).  The querying costs of $S'$ are at most those of $S$
because in any given round, the probability of any given number of bidders
bidding is the same in both mechanisms (cf.~Lemma~\ref{lemma:descending}), 
and $S$ cannot terminate (with allocation) before at least one bidder has bid. 
%($S$ may continue asking further queries after that.)
Moreover, the expected virtual valuation of the winning bidder is at
least as high under $S'$ as it is under $S$.
Hence, by Myerson's result, expected total bidder spending is at least 
as high under $S'$ as it is under $S$.
Therefore,
 $E_{S'}[\text{profit}]
= E_{S'}[\text{bidder spending}] - E_{S'}[\text{total cost}]
 \geq E_{S}[\text{bidder spending}] - E_{S}[\text{total cost}]
= E_{S}[\text{profit}]$, so $S'$ must also be optimal.
%That says, if there's no reported bidders yet, we will always ask the
%descending query which has the same length as the query of $S$. And we pretend
%that we asked the same query as $S$ so we can continue to ask $S$ what's the
%next query length. Once we get reply in $S'$, we terminate the mechanism
%immediately and allocate the item to the replied bidder with highest valuation
%with probability 1.  Note that we may have $|Q'_i| = |Q_i| = 0$ which means
%both mechanisms terminate after $i$ queries without any reply and allocation.
%It's clear that our new mechanism won't cause more cost than original
%mechanism.  And our new mechanism's allocation rule will get at least as high
%total spending as original mechanism because it makes allocation probability of
%high value bidders as much as possible. Therefore our new mechanism, which
%satisfies relaxed efficiency constraint with some low value $l$, is also
%optimal.
%Firstly, note that (at least one) optimal allocation rule $p$ will have at most
%one possible winner, i.e. there can't be $p_i, p_j > 0$ if $i \neq j$. If not,
%without loss of generality let's suppose $v_i \geq v_j$ and $p_i, p_j > 0$. We
%can shift $j$'s probability to $i$, making $p_i' = p_i + p_j$ and $p_j' = 0$.
%Since it can't allocate blindly, this won't increase the cost and actually it
%can potentially lower the cost because we don't need bidder $j$ to reply.  The
%total spending is also non-decreasing by this change in regular cases thus the
%profit is non-decreasing. Keep on doing this change will eventually give us an
%optimal allocation rule with only one possible winner.
%
%Secondly define active region $A$ as
%\begin{align*}
%  A = \{ v_i ~|~ \exists (v_1, \ldots, v_i, \ldots, v_n), p_i > 0 \}
%\end{align*}
%
\end{proof}

%For simplicity, we assume regularity and will not mention virtual
%valuation below.  It's easy to extend our result to general cases by mapping
%all values to virtual values and ask broadcast queries according to virtual
%values.



%We have already narrowed down optimal mechanism to
%relaxed efficient mechanisms and by Theorem~\ref{theorem:equivalence},
%it is straightforward to see

%\begin{corollary}
%For mechanisms with a fixed low value $l$, the maximum profit is
%achieved when the mechanism minizes the cost.
%\end{corollary}

%Our next question is naturally: what is the cost minimized mechanism
%given a low value $l$. 
%A similar lemma can be proved using almost identical technique to Lemma~\ref{lemma:uniform}.
%Thus for space limit, we will not elaborate it again. 

%\begin{lemma}\label{lemma:lowest_type}
%Suppose that there are two cases $n, F_1, f_1, l_1$ and $n, F_2, f_2, l_2$
%where $n$ is the number of values for both cases, $F_i, f_i$ are CDF and PDF
%of the $n$ i.i.d. values in case $i$, $l_i$ is the low value for case $i$.
%If $F_1(l_1) = F_2(l_2)$, then these two cases have the same minimum cost
%to find the maximum value above the low value $l_i$.
%\end{lemma}

%Finally, we conclude

%\begin{theorem}

%MVAs have the minimum cost among all mechanisms with a low value $l$. Thus
%they are optimal.

%\end{theorem}

%\begin{proof}
%A special case of this theorem when $l = 0$ is Theorem~\ref{theorem:MVA_eq}.
%We proved that special case by introducing Lemma~\ref{lemma:uniform} and
%\ref{lemma:descending}. To prove the general cases with arbitrary $l$, we just
%need to revise Lemma~\ref{lemma:uniform} a little to
%Lemma~\ref{lemma:lowest_type}. All other part of the proof remains similar. For
%space limit, the detailed proof is omitted.
%\end{proof}

For a given MVA, let $l = \inf_i a_i$ be the value below which we do not
allocate.  It is easy to see that if $l>0$ and $b>0$, then the sequence of
$a_i$ will be finite (and the last one will be $l$). This is because if the
sequence were infinite, there would be a nonzero probability of asking
infinitely many broadcast queries.  We next discuss how to optimize, given
$l$, the remaining $a_i$.  We note that when $l$ is fixed, this comes down
to a query cost minimization problem similar to those studied earlier in
this paper, and we can assume without loss of generality that the
distribution is uniform by an appropriate transformation.  To find the
optimal $l$, we resort to brute-force search over all (discretized) values
above Myerson's reserve value.

%Finally, we will consider optimizing the low value $l$.


%hen the only parameters we are going to determine for the
%specific optimal MVA are 1) the low value $l$; 2) the descending query
%thresholds $a_1, a_2, a_3, \ldots$.
%When we later investigate such parameters that minimizes the cost, we will
%also assume uniform distribution $F(x) = x$ in default because distribution will not
%change this minimum cost and we can always adapt an optimal MVA for uniform distribution
%to an optimal MVA for any distribution easily.

%\subsection{Experiments to Discover Optimal MVA with a Given Low Value}
%
%To discover the specific MVA that is optimal, we first try to identify the
%optimal thresholds $a_i$ given a low value $l$  (recall that in $i$-th round,
%MVA will ask all bidders whose valuation is within $[a_i, a_{i-1})$ to bid).
%If we can write the minimum cost $C^*$ as a function of $n, \rho, l$ (recall
%that $\rho = b/c$ is the ratio between broadcast and bid cost), we may then
%determine the optimal $l$ by that.
%
%%In the special case that we studied in previous section where $l = 0$
%%(efficiency is enforced), the optimal thresholds can be easily described as a
%%single parameter $\alpha$. This strategy will not work when $l > 0$ (we assume uniform
%%distribution in default). Obviously that $a_i \geq l$,
%%thus we cannot let $a_i = \alpha a_{i-1}$ since $\lim_{i \rightarrow \infty} a_i
%%= 0 < l$.  Additionally, if we revise the equation by letting $a_i-l = \alpha
%%(a_{i-1}-l)$, we will get a positive possibility $F(l)$ that we would ask
%%infinite many broadcast queries, which is even worse.
%
%As it is not immediately clear what optimal thresholds should be like, we
%present a simple algorithm to calculate such thresholds numerically. We firstly
%discretize the continuous valuation $[0, 1)$ to $D$ discrete values $\{0, 1, \ldots,
%D-1\}$. That means, the original valuation $v$ will be transformed to integer
%value $\hat v = \lfloor v D \rfloor$. Then we use dynamic programming to
%inductively calculate $\hat x_{\hat h}$, the length of next optimal descending
%query $[\hat h-\hat x_{\hat h}, \hat h)$ to ask, conditional on that we have
%already queried $[\hat h, D)$ and no one replies.
%
%\begin{algorithm}
%    \caption{Calculate discretized best query lengths}\label{algo:discrete}
%    \begin{algorithmic}[1]
%        \Require{$\hat l$ is the discretized low value, $\rho$ is the ratio between broadcast and bid cost,
%        $n$ is the number of bidders, $D$ is the maximum discretized valuation}
%        
%        \Function{BestQueryLengths}{$\hat l$, $\rho$, $n$, $D$}
%            \State $\hat x_{\hat l} \gets 0$
%            \State $C_{\hat l} \gets 0$
%            \For{$\hat h={\hat l}+1 \mbox{ to } D$}
%                \State $\hat x_{\hat h} \gets \displaystyle
%                  \operatorname*{arg\,min}_{1 \leq \hat x \leq \hat h-l} \rho + n
%                  \frac{\hat x}{\hat h} + (\frac{\hat h-x}{\hat h})^n C_{\hat h-\hat x}$
%                \State $C_{\hat h} \gets \rho + n \frac{\hat x_{\hat h}}{\hat h} +
%                  (\frac{\hat h-\hat x_{\hat h}}{\hat h})^n C_{\hat h-\hat x_{\hat h}}$
%            \EndFor
%            \State \Return $\hat x$
%        \EndFunction
%    \end{algorithmic}
%\end{algorithm}

%\begin{figure*}
%\centering
%    \subfigure[$n = 10, b = 0.2, c = 0.1$]{
%      \includegraphics[trim=0mm 5mm 5mm 15mm, clip, width=.32\linewidth]{figures/10-0.200000-0.100000.eps}
%      \label{fig:CSP-l-2-1}
%    } 
%    \subfigure[$n = 10, b = 0.5, c = 0.1$]{
%      \includegraphics[trim=0mm 5mm 5mm 15mm, clip, width=.32\linewidth]{figures/10-0.500000-0.100000.eps}
%      \label{fig:CSP-l-5-1}
%    }
%    \subfigure[Suboptimality, $n = 10, b = 0.2, c = 0.1$]{
%      \includegraphics[trim=0mm 5mm 5mm 15mm, clip, width=.32\linewidth]{figures/suboptimality.eps}
%      \label{fig:suboptimality}
%    }
%    \caption{Optimal MVA's cost, spending, profit over $l$, $n$ i.i.d. uniform distributed bidders,
%      broadcast $b$ and bid cost $c$}
%\end{figure*}

%Algorithm \ref{algo:discrete} runs in time $O(D^2)$. Having $\hat x$, we can
%then infer the best strategy $x$ for original continuous problem by converting
%$\hat h, \hat x$ back to $h, x$ and using them to interpolate continuous
%strategy.  The larger $D$ is the more accurate it will be. But it will also
%require more running time.  Running this for case $l = .5, \rho = 2, n = 10, D
%= 1000$ we get $x$ showed in figure \ref{fig:x-h}. It seems that $x$ is a
%piecewise linear function over $h$.  For those $h$ which is close to
%$l$, obviously that the optimal strategy should be $x = h - l$,
%which means using only one query to explore all potential bidders. But it is
%unclear why $x$ is linear when the best strategy is using multiple queries to
%explore the valuation range.
%
%Another way to plot the graph is to normalize $x$ and $l$ so that $h$ becomes
%$1$ since our model is $v_i \in [0, 1)$. It is showed in figure \ref{fig:x-l}.
%This again looks like a piecewise linear function.  A more interesting
%observation is that the left-most piece is quite a long straight line $x =
%1-\alpha$. Thus it seems that $x = 1-\alpha$ is optimal for quite a lot $l$ which is not
%far from $0$. Here the $\alpha$ is the the optimal $\alpha$ of $\alpha$-MVA if
%we set $l = 0$.

\subsection{Optimal MVAs Given a Positive Low Value}\label{sec:general_analysis}

\begin{figure}
    \includegraphics[trim=0mm 5mm 5mm 15mm, clip, width=\linewidth]{figures/10000-500-2-1-10}
    \caption{Optimal first-query-length $x$ ($=1-a_1$) as a function of
      $l$. ($\rho=2$, $n=10$, and $[0,1)$ is discretized into $1000$ pieces.)}
    \label{fig:x-l}
\end{figure}


We now consider how to minimize cost for a given low value $l>0$ of the
MVA, restricting our attention to uniform distributions without loss of
generality.  A key observation is that if all bidders remain silent to a
query, then we can renormalize the resulting conditional distribution to be
over $[0,1)$ as we did in the efficient case; however, in this case, the
resulting problem is not identical to the original, but rather has a larger
value of $l$.  Using this insight, we can solve a discretized version of
the problem, using dynamic programming to compute the optimal first query
as a function of (a discretized set) $l$, starting with large $l$ and
working our way down.
%Before an analytical treatment, we first conduct an experiment to compute the
%optimal MVA approximately for getting some insights. In that experiment, we
%discretize the value into fine grids and then use dynamic programming to
%compute the optimal first-query-length over different $l$ (this is sufficient o derive the whole
%optimal MVA because a failed query is equivalent to increase the $l$ after
%renormalizing). 
The result is plotted in Figure~\ref{fig:x-l} and suggest that a result as
elegant as for the efficient case is out of the question.  Nevertheless,
some sense can be made of it.  The graph is {\em almost} piecewise linear.
The rightmost piece is linear and corresponds to asking a single query at
$l$.  The second-to-rightmost piece is not exactly linear, but corresponds
to asking a query that, if unsuccessful, will result in being on the
rightmost piece.

%and it seems to be much more complicated than $\alpha$-MVA but there might
%still be hope to get a nice analytical result: it seems like a piecewise linear
%function. Specifically, we cannot use a single $\alpha$ to describe such
%optimal MVA, but perhaps we can use a sequence of $\alpha$ to describe it. Now
%let us take an analytical treatment.

%Figure \ref{fig:x-h} shows that the optimal MVA with a low value $l > 0$ is
%much more complicated but there might still be hope to get a nice analytical
%result: piecewise linear function. That is, we cannot use a single $\alpha$ to
%describe such optimal MVA, but perhaps we can use a sequence of $\alpha$ to
%describe it. Now let us take an analytical treatment.




We know that with $l>0$, in an optimal query strategy, at most a finite
number $k$ of queries will be asked.  ($k$ may depend on $n$ and $l$.)  Let
us first consider how to optimize the strategy for a given $k$ (which will
remove the discontinuities).
%The first key to analyze the optimal MVA with $l > 0$ is to utilize
%the fact that there is a maximal number of rounds to exploit the whole
%reportable valuation range $[l, 1)$. Let us call that
%number $k$.\footnote{We have argued this before: if such $k$ does not exist, or equivalently
%the maximum number of rounds is unbounded, the cost will be infinite as the possibility that no
%values lie in $[l, 1)$ is positive.}
Let $\boldsymbol a = (a_0, a_1, a_2, \ldots, a_k)$ be the vector of
thresholds in this optimal MVA (where $a_0 = 1$ for convenience, and $a_k =
l$).
% so in $i$-th
%round the query would be $[a_i, a_{i-1})$.
Let $C(\boldsymbol a, k, b, c,
n)$ be the expected total communication cost 
for the MVA query strategy
$k, \boldsymbol a$.
%when there are $n$
%i.i.d.  $[0, 1)$-uniform bidders (note that $l, h$ are implicitly defined by
%$a_k, a_0$). 

%If we can get a neat form of $C$, we can use $\frac{\partial
%C}{\partial a_i} = 0 $ to characterize optimal MVA, as we did in 
%\ref{sec:alpha-MVA}.\footnote{It is easy to see that boundary cases $a_i = a_{i%-1},
%a_{i+1}$ are not optimal too.}
%Thus the second key is to represent this $C$. 
%Rather than
%considering one round after another recursively as we did before, we now consider all
%rounds together. 
Let $C^i$ denote the total communication cost that we incur in
round $i$ and let 
%(the broadcast
%of that round and the bid cost charged in that round) and 
$v^* = \max_i v_i$. Then:
% expected cost
%would be sum of expected cost of each round:
\begin{align}
C(\boldsymbol a, k, b, c, n) &= \sum_{i=1}^k E[ C^i ] \nonumber \\
  &= \sum_{i=1}^{k} \Pr\big( v^* < a_{i-1} \big) E[C^i ~|~ v^* < a_{i-1}] \nonumber \\
  &= \sum_{i=1}^{k} \frac{a_{i-1}^n}{a_0^n} \left( b + \frac{a_{i-1}-a_{i}}{a_{i-1}} cn \right)
  \label{eq:C_general_simplified}
\end{align}

Taking the derivative, we get
\begin{align}
 \frac{\partial C}{\partial a_i} = \frac{
	n(nc+b)a_i^{n-1}-n(n-1)ca_{i+1}a_i^{n-2}-nca_{i-1}^{n-1} }{a_0^n}
	\label{eq:diff_C_general}
\end{align}

Setting this to zero for all $i$ ($1 \leq i \leq k-1$) will give the
optimal solution (the boundary cases are clearly not optimal).

%Unfortunately, equation
%\ref{eq:diff_C_general} is not neat enough to get a piecewise linear query length.
%Recall that in previous subsection, the experiment seems to show that query len%gth $x$ is
%piecewise linear over $l$, which means $a_1 = a_2+x = l+x$ must also be
%piecewise linear over $a_2 = l$.  
In special cases, we can solve this analytically: for example, 
for $k =
2, n = 3$ we have: $a_1 =
(\sqrt{{a_2}^{2}\,(\rho+3)+{a_0}^{2}}+a_0)/(\rho+3)$ (where $\rho=b/c$), which
indeed is close to linear (when $a_0 \geq a_2$), but not quite.
%Anyway, by
%definition we have $a_1 \geq a_2$. And the former equation indeed looks very
%linear when $a_1 \geq a_2$.
%Though we failed characterizing the optimal MVA using piecewise linear
%functions, equation \ref{eq:C_general_simplified} gives us a better way to
%calculate thresholds $a_i$. 
In general, we use 
an R package called BB~\cite{Varadhan2009:BB} to
solve these systems of equations. 
This requires us to 
%Before throw those equations to that
%package, we have to
 first choose $k$ and an initial guess for $\boldsymbol a$.
We thus turn our attention to choosing $k$.  We need the following lemma:

%We found a lemma that's very useful for deciding $k$:

\begin{lemma}\label{lemma:thresholds}
Consider two vectors $\boldsymbol a = (a_0, \ldots, a_{k_1})$ and
$\boldsymbol a' = (a'_0, \ldots, a'_{k_2})$ and suppose they are optimal
for $l=a_{k_1}$ and $l=a_{k_2}$, respectively.  Then it cannot be the case
that  $p_2 \leq q_2 < q_1 < p_1$
where $p_2 = a_i$, $p_1= a_{i-1}$ are two consecutive thresholds in the
first sequence and  $q_2 = a'_j$, $p_1= a'_{j-1}$ in the second sequence.
\end{lemma}

\begin{proof}
Let $C(l)$ denote the optimal cost for finding the maximum value above low
value $l$.
%(suppose $h, n, \rho$ and everything else are constants now). Note
%that thresholds $a_0, \ldots, a_i$ must be optimal thresholds for $l = a_i$,
%otherwise $a_0, \ldots, a_k$ can't be optimal for $l = a_k$.  Similarly,
%$a'_0, \ldots, a'_j$ must be optimal thresholds for $l = a'_j$.  
Then by the optimality of the two sequences we have
%from optimality of $a_0, \ldots, a_i$ and $b_0, \ldots, b_j$ we have:
\begin{align*}
%  C(b_{j-1}) + b_{j-1}^n [\rho+n(b_{j-1}-b_j)] \leq C(a_{i-1}) + a_{i-1}^n [\rho + n(a_{i-1}-b_j)]\\
%  C(a_{i-1}) + a_{i-1}^n [\rho+n(a_{i-1}-a_i)] \leq C(b_{j-1}) + b_{j-1}^n [\rho + n(b_{j-1}-a_i)]
  C(q_1) + q_1^n [\rho+n(q_1-q_2)] \leq C(p_1) + p_1^n [\rho + n(p_1-q_2)]\\
  C(p_1) + p_1^n [\rho+n(p_1-p_2)] \leq C(q_1) + q_1^n [\rho + n(q_1-p_2)]
\end{align*}
Adding these two inequalities and performing some cancellations gives
$p_1^n \leq q_1^n$, which contradicts $q_1 < p_1$.
\end{proof}


%yuqian: l is confusing
\begin{theorem}\label{theorem:k_bounds}
$k_\alpha^+ = \left\lceil \log_{\alpha} \left(1/l\right) \right\rceil$ and 
$k_\alpha^- \left\lfloor \log_{\alpha} \left(1/l\right) \right\rfloor$ are upper
and lower bounds for the optimal $k$. Here, $\alpha$ is the optimal $\alpha$
from the
$\alpha$-MVA (when $l = 0$). 
\end{theorem}
\begin{proof}
For the sake of contradiction, assume $k > k_\alpha^+$ for optimal thresholds
$(a^*_0, a^*_1, a^*_2, \ldots, a^*_k)$ (where $a^*_0 = 1, a^*_k = l$).  
Points $a_0 = \alpha^0, a_1 = \alpha^1, \ldots, a_{k_\alpha^+} = \alpha^{k_\alpha^+}$
constitute an optimal sequence for low value $l'=\alpha^{k_\alpha^+}$ (if there were a
better sequence, we could improve on the $\alpha$-MVA by starting
with that sequence instead).
This sequence also
splits interval $[l', 1)$ into $k_\alpha^+$ subintervals $[a_i, a_{i-1})$, which
together contain $k$ thresholds $a^*_1, \ldots, a^*_k$. Since $k > k_\alpha^+$, at
least one subinterval $[a_i, a_{i-1})$ contains two thresholds $a^*_j,
a^*_{j-1}$, so we have $a_i \leq a^*_j < a^*_{j-1} < a_{i-1}$.  This
contradicts with Lemma~\ref{lemma:thresholds}.
The proof that $k_\alpha^-$ constitutes a lower bound is similar.
\end{proof}


%From that we derive an upper bound for $k$. Intuitively, it says we will need
%less rounds if we have less reportable range (a greater $l$).

%\begin{lemma}\label{lemma:k_upper}
%$k_\alpha = \left\lceil \log_{\alpha} \left(1/l\right) \right\rceil$ is an
%upper bound for the optimal $k$. Here $\alpha$ is the optimal $\alpha$ for
%$\alpha$-MVA when $l = 0$. 
%\end{lemma}

%\begin{proof}
%We will prove by contradiction. Assume $k > k_\alpha$ for optimal thresholds
%$(a^*_0, a^*_1, a^*_2, \ldots, a^*_k)$ where $a^*_0 = 1, a^*_k = l$ as defined.%  Points
%$a_0 = \alpha^0, a_1 = \alpha^1, \ldots, a_{k_\alpha} = \alpha^{k_\alpha^+}$
%constitute an optimal sequence for $l=\alpha^{k_\alpha^+}$ (if there were a
%better sequence, we could improve on the $\alpha$-MVA for $l=0$ by starting
%with that sequence instead).
%This sequence also
%splits interval $[l, 1)$ into $k_\alpha^+$ subintervals $[a_i, a_{i-1})$, which
%together contain $k$ thresholds $a^*_1, \ldots, a^*_k$. Since $k > k_\alpha^+$,% at
%least one subinterval $[a_i, a_{i-1})$ contains two thresholds $a^*_j,
%a^*_{j-1}$, so we have $a_i \leq a^*_j < a^*_{j-1} < a_{i-1}$.  This
%contradicts with Lemma~\ref{lemma:thresholds}.
%The proof that 
%\end{proof}



%Having this upper bound, we can eigther bruteforcely search all $k$ between $1$
%and $k_\alpha$, or use ternary search [cite wiki?] to get optimal $k$ in
%$O(\log k_\alpha)$ time if we can prove it is unimodal.\footnote{We did not
%prove that it is unimodal but experiments seems to support this property.}
%But in light of the proof above, we actually could have something much better:

%\begin{theorem}\label{theorem:k_bounds}
%$\left\lceil \log_{\alpha} \left(1/l\right) \right\rceil$ and 
%$\left\lfloor \log_{\alpha} \left(1/l\right) \right\rfloor$ are upper
%and lower bounds for the optimal $k$. 
%\end{theorem}

%\begin{proof}
%We have proved the upper bound in Lemma~\ref{lemma:k_upper}. Similarly, if the %lower bound
%does not hold, we have $a^*_j = p_2 \leq \alpha^i = q_2 < \alpha^{i-1} =
%q_1 < a^*_{j-1} = p_1$ which violates Lemma~\ref{lemma:thresholds}. 
%\end{proof}


%The significant difference only occur when low value $l$ is a little below
%$\alpha$ and this is not likely to occur when $n$ is large where $\alpha$ is
%much closer to $1$ than $l$.

%The next important thing is the initial thresholds $\boldsymbol a$. A bad
%choice may lead to much more computation and even non-convergence. For example,
%the trivial uniform $a_i = (1-i/k)a_0 - (i/k) a_k$ is a bad initial guess. We
%find the initial guess $a_i = \alpha^i$ (the same $\alpha$ of $k_\alpha$) to be
%very efficient.  Let us call this MVA with thresholds $\alpha, \alpha^1,
%\ldots, \alpha^{k-1}$ where $\alpha^{k-1} \geq l, \alpha^k < l$ an
%$\alpha$-cutoff-MVA, similar to what we did in previous section
%\ref{sec:eff_experiment}.  One explanation about its good performance is that
%these initial thresholds doesn't violate Lemma~\ref{lemma:thresholds} (while
%the uniform thresholds do). Thus it's more likely to be close to actual optimal
%thresholds.
%It is
%suggested by experiments showed in figure \ref{fig:x-l} where query length $x$
%seems to be $1-\alpha$ for a lot of $l$. 
%In experiments, this $\alpha$-cutoff-MVA's profit is pretty good as shown
%in figure \ref{fig:cutoff}. In most cases its profit is very close to optimal.
%The significant difference only occur when low value $l$ is a little below
%$\alpha$ and this is not likely to occur when $n$ is large where $\alpha$ is
%much closer to $1$ than $l$.

%\subsection{Choosing Low Value}

%Having $k$ and $a_i$, we are still one step away from optimal MVA: choosing the low
%value $l$. It is obvious to see that optimal cost $C$ is non-increasing as $l$
%increases. By Myerson's optimal auction theory and Theorem~\ref{theorem:equivalence}, setting virtual value of $l$ to be $0$ will yield
%the maximum total spending. Name such $l$ as $l_0$. We then conclude that
%optimal $l$ must satisfy $l \geq l_0$. The
%question is, how to search or determine optimal $l$. Let us first check the simple
%case when the value distribution is uniform.

%Figure \ref{fig:CSP-l-2-1} and \ref{fig:CSP-l-5-1} plot cost, spending and profit
%over $l$. It is clear in figure \ref{fig:CSP-l-5-1} that increasing $l$ from $0.5$ to about $0.8$
%will get a significant profit increase. However, it is not so clear in these two plots
%whether profit is unimodal and whether we can do ternary search.\footnote{Unlike $k$ which is
%an integer with a fairly small upper bound, $l$ is continuous over $[0.5, 1)$, 
%thus a ternary search is more needed.}
%To see it more clear, we plot figure \ref{fig:suboptimality},
%which transforms the cost, spending and profit to their corresponding suboptimality, i.e.
%the distance between the specific value and the optimal value (to make the log-scale work
%for distance $0$, we add some small constant to that suboptimality). Thus, the new plot will
%preserve the peaks and global optimal point as the lowest point.

%From figure \ref{fig:suboptimality}, the cost is not unimodal over $l$ and it is quite wierd.
%Thus in later experiments, we are just going to brute forcely search over all possible $l$ from $0.5$ to $1$,
%with a search increment of $0.01$.

\subsection{Experiments}

\begin{figure}
\centering
    \includegraphics[trim=0mm 0mm 5mm 7mm, clip, width=\linewidth]{figures/cutoff_.2_.1_15.eps}
    \caption{The profit of the optimal MVA and the $\alpha$-cutoff-MVA are plotted as
    solid lines.  (The optimal value of $l$ is determined by brute-force
    search.)  $\alpha$ and $l$ are plotted in dashed lines, to illustrate
    that the the only cases where the $\alpha$-cutoff-MVA performs
    significantly more poorly are when $\alpha$ (or $\alpha^2$) are slightly
    above $l$, because in this case the $\alpha$-cutoff-MVA is often forced to
    ask another query to get below $l$.}\label{fig:cutoff}
\end{figure}

\begin{figure*}
\centering
  \subfigure[profit]{
    \includegraphics[trim=0mm 5mm 5mm 15mm, clip, height=.3\linewidth, width=.4\linewidth]{figures/profit_.1.eps}
    \label{fig:general_profit}
  }
  \subfigure[low value]{
    \includegraphics[trim=0mm 5mm 5mm 15mm, clip, height=.3\linewidth, width=.4\linewidth]{figures/l_.1.eps}
    \label{fig:general_l}
  }
  \caption{The expected profit, as well as the value of $l$ (the lowest
    valuation that may bid), for various mechanisms as a function of $n$.
    We have
  broadcast cost $b = 0.1$ and  seller and bidder bid costs $\beta_1 =
  \beta_2 = 0.05$ (thus $c = \beta_1+\beta_2 = 0.1$).}\label{fig:general}
\end{figure*}
%Done vc: on left hand side add ``MVA'', on right hand side don't mention l
%(just optimal)

We continue to evaluate on a uniform distribution over valuations.
By Theorem~\ref{theorem:k_bounds}, we only need to try two values of $k$.
For the initial thresholds $\boldsymbol a$, Lemma~\ref{lemma:thresholds}
suggests initializing $a_i = \alpha^i$.  We refer to this initialization as
the $\alpha$-cutoff-MVA.  Indeed, this initialization allows the solver to
converge to the optimal solution, unlike simple heuristics such as
spreading the $a_i$ uniformly.  In fact, even the $\alpha$-cutoff-MVA by
itself (without running the solver) already performs close to optimality,
as shown in Figure~\ref{fig:cutoff}.


Finally, we compare the profit of our mechanisms to that of mechanisms that
use only a single round, such as Myerson's mechanism.\footnote{We do not
  consider other, heuristic querying strategies here; intuition about how
  these perform can be obtained from the experiments in
  Section~\ref{sec:eff_experiment}.}  These experiments 
give insight into whether setting $l$ correctly and  not ignoring the
communication costs are important.
%Finally we are going to compare profit of different mechanisms in general settings.
%To keep it simple, we still use a uniform valuation distribution for all
%experiments.  As Theorem~\ref{theorem:equivalence} shows, the profit is simply
%spending minus cost where spending is solely determined by $l$. In fact, the
%total spending will not be very sensitive to this $l$ when $n$ is large (except
%that $l$ is very close to $1$) and we will see this in later comparisons. Thus
%most experimental comparisons that we have done for cost in section
%\ref{sec:eff_experiment} would also give us a lot information for profit
%comparison. As a result, we will compare mechanisms very different from those
%in section \ref{sec:eff_experiment}. Specifically, we will not be interested in
%$k$-MVA where $k$ is very limited. Instead, we are going to compare how $l$
%is going to affect the profit and how much profit we lose if we ignore the cost.
If we ignore communication costs, 
the Myerson auction (a single-shot Vickrey
auction with reserve price $0.5$) is optimal.
%Done vc: singleshot -> single-shot
But when communication costs exist, this is not necessarily true.  If
$\beta_1 > 0$ and $\beta_2 = 0$, one may
benefit from setting a somewhat higher reserve price to reduce the number
of bids.  On the other hand, if $\beta_1=0$ and $\beta_2 > 0$, bidders just
barely above the reserve price will not bid, and one may want to set the
reserve price lower. Hence, we also compute the optimal reserve price for a
single-shot auction (by
brute force) and compare to it.

%Thus we will compare this singleshot mechanism, as well as its variants, the
%singleshot Vickrey auction with $0$ reserve price. But be aware of that reserve
%price is not equivalent with low value $l$  when cost exists. To make it more fair,
%we add one more singleshot Vickrey auction whose reserve is set to be optimal
%among all singleshot Vickrey auctions (i.e. we optimize $l$ for this particular
%singleshot mechanism).
%One may also suspect whether it is good enough to set low value $l$ to be $0.5$
%in such singleshot Vickrey auction, since it will bring us maximal total
%spending. The answer is no, because its bid cost is $0.5 n \times c$, which
%grows way too large when $n$ is large.

The results are shown in Figure~\ref{fig:general}. 
%As shown in
%profit comparison figure \ref{fig:general_profit}, t
On the MVA side, the profit for using the optimal $l$,
$l = 0$, and $l = 0.5$ become close very quickly as $n$ grows.
% and they are
%almost identical for $n \geq 8$ in this experiment setting. 
Hence, the choice of $l$ is relatively unimportant
for large $n$. 
The single-shot mechanisms, on the other hand, perform significantly worse,
and the choice of reserve price is quite important.
%However, if we use singleshot
%mechanism (which is optimal if cost does not exist), 
If we set the reserve price low so that even bidders with low valuations
bid, the communication costs will get large.
If we set the reserve price high, only bidders with very high valuations
bid, and total spending is low.  The results show that attempting strike a
balance and setting the reserve price in between is optimal, but not very effective. 

%(1) is because bidders will be reluctant to bid unless their valuation is
%very close to $1$, as they will certainly have to pay the bid cost and face
%significant competition.
%This is because the bid cost will drive low value $l$ very
%close to $1$ thus lower the total spending significantly. 
%For example, even if
%we set the reserve price to $0$, when $n = 10$, $l$---the lowest value at
%which a bidder will bid---will be between $0.6$ to $0.8$.



 
%The optimal reserve price is still a bit above $0$.



%Setting a
%reserve price of $0.5$ results in even larger $l$.


%The optimal reserve price $0.5$ becomes the worst as its $l$ is too high. 
%Even if we adapt our reserve price to optimal one, the singleshot mechanism is
%still not so good because it cannot balance the total spending and bid cost,
%i.e. it either makes $l$ close to $1$ to lose a lot total spending, or makes
%$l$ close to $0.5$ to cause a big bid cost.
